{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 13:13:13.612659: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-26 13:13:13.612680: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-02-26 13:13:13.612683: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-02-26 13:13:13.612732: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-26 13:13:13.613041: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "a = tf.convert_to_tensor(([0,1,2,3,4,5]), np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([0., 1., 2., 3., 4., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numpy()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "path = \"assets/\"\n",
    "\n",
    "files = os.listdir(path)\n",
    "x = np.array([0])\n",
    "for file in files:\n",
    "    if not \".DS\" in file:\n",
    "        audio, sr, = librosa.load(path + file)\n",
    "        x = np.concatenate((x, audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3583747,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 12:53:05.121663: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-26 12:53:05.121695: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-02-26 12:53:05.121698: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-02-26 12:53:05.121932: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-26 12:53:05.122124: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([3583747])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tf = tf.convert_to_tensor(x, np.float32)\n",
    "data_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "n = tf.signal.stft(data_tf,2048,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude_spectrograms = tf.abs(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to get all the fft frames and organise them into sequence batches\n",
    "start = 0\n",
    "sequence_length = 40\n",
    "end = magnitude_spectrograms.shape[0] - sequence_length - 1\n",
    "step = 1\n",
    "x_frames = []\n",
    "y_frames = []\n",
    "for i in range(start, end, step):\n",
    "    done = int(float(i) / float(end) * 100.0)\n",
    "    sys.stdout.write('{}% data generation complete.   \\r'.format(done))\n",
    "    sys.stdout.flush()\n",
    "    x = magnitude_spectrograms[i:i+sequence_length]\n",
    "    y = magnitude_spectrograms[i+sequence_length]\n",
    "    x_frames.append(x)\n",
    "    y_frames.append(y)\n",
    "x_frames = np.array(x_frames)\n",
    "y_frames = np.array(y_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate        = 0.001\n",
    "amount_epochs        = 500\n",
    "batch_size           = 64\n",
    "loss_type            = \"mse\"\n",
    "weight_decay         = 0.0001\n",
    "\n",
    "\n",
    "\n",
    "# Recurrent Neural Network\n",
    "rnn_type             = \"lstm\"\n",
    "number_rnn_layers    = 3\n",
    "rnn_number_units     = 128\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization(input_shape=[x_frames.shape[1], x_frames.shape[2]]))\n",
    "\n",
    "for layer in range(number_rnn_layers):\n",
    "    return_sequence = False if layer == (number_rnn_layers - 1) else True\n",
    "    model.add(tf.keras.layers.LSTM(rnn_number_units, return_sequences= return_sequence))\n",
    "    \n",
    "model.add(tf.keras.layers.Dense(y_frames.shape[1]))\n",
    "\n",
    "model.add(tf.keras.layers.Activation('linear'))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer=opt, loss=loss_type)\n",
    "\n",
    "# this model trains much much faster than the prior models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_frames, y_frames, batch_size=batch_size, epochs=amount_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your model\n",
    "model.save(\"myModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your model\n",
    "model = tf.keras.models.load_model(\"myModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_samples      = 1\n",
    "sequence_length_max = 1000\n",
    "impulse_scale       = 1.0\n",
    "random_chance       = 0.1\n",
    "random_strength     = 1.0\n",
    "window_size = 1024\n",
    "\n",
    "dimension1 = x_frames.shape[1]\n",
    "dimension2 = x_frames.shape[2]\n",
    "shape = (1, dimension1, dimension2)\n",
    "\n",
    "audio = []\n",
    "\n",
    "for i in range(amount_samples):                                                                                                                                   \n",
    "    \n",
    "    random_index = np.random.randint(0, (len(x_frames) - 1))                                                                                                                    \n",
    "    impulse = np.array(x_frames[random_index]) * impulse_scale\n",
    "    predicted_magnitudes = impulse\n",
    "    \n",
    "    for j in range(sequence_length_max):\n",
    "        prediction = model.predict(impulse.reshape(shape))\n",
    "        predicted_magnitudes = np.vstack((predicted_magnitudes, prediction))\n",
    "        impulse = predicted_magnitudes[-sequence_length:]\n",
    "        \n",
    "        if (np.random.random_sample() < random_chance) :\n",
    "            random_index = np.random.randint(0, (len(x_frames) - 1))                                                                                                                    \n",
    "            impulse = np.array(x_frames[random_index]) * impulse_scale * random_strength\n",
    "            #predicted_magnitudes = impulse\n",
    "        \n",
    "        done = int(float(i * sequence_length_max + j) / float(amount_samples * sequence_length_max) * 100.0) + 1\n",
    "        sys.stdout.write('{}% audio generation complete.   \\r'.format(done))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        #predicted_magnitudes = np.array(predicted_magnitudes).reshape(-1, window_size+1) \n",
    "        predicted_magnitudes = np.array(predicted_magnitudes).reshape(-1, window_size+1)                                                                           \n",
    "        #audio += [librosa.griffinlim(predicted_magnitudes.T)]\n",
    "        #audio+=[predicted_magnitudes.T]\n",
    "    new_sample = [librosa.griffinlim(predicted_magnitudes.T)]\n",
    "    audio.append(new_sample)\n",
    "audio = np.array(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "Audio(audio[0], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
